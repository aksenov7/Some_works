{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    " \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/aleksandr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = create_connection(path + 'ertelecom_base.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat',), ('result',)]\n"
     ]
    }
   ],
   "source": [
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract first level domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract as tld\n",
    "def get_top_level_domain(domain):\n",
    "    domain = tld.extract(domain)\n",
    "    domain = '.'.join(domain[-2:])\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make generator for read own base by batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import generators    # needs to be at the top of your module\n",
    "\n",
    "def ResultIter(cursor, arraysize=100000):\n",
    "    'An iterator that uses fetchmany to keep memory usage down'\n",
    "    while True:\n",
    "        results = cursor.fetchmany(arraysize)\n",
    "        if not results:\n",
    "            break\n",
    "        for result in results:\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make diff with own base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diff(domains):\n",
    "    start = dt.now()\n",
    "    my_set = set(domains)\n",
    "    cursor.execute(\"SELECT domain FROM result ORDER BY domain;\")\n",
    "    n = 0\n",
    "    for result in ResultIter(cursor):\n",
    "        my_set.difference_update(set(result))\n",
    "    print(len(my_set))\n",
    "    print(dt.now() - start)\n",
    "    return my_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ru, rf, su domain from reg.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.626089\n",
      "(5836461,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2013481           jahve.ru\n",
       "5730307         anycast.su\n",
       "5731894          artium.su\n",
       "5734627         azimuth.su\n",
       "5735249    banana-grief.su\n",
       "Name: domain, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = dt.now()\n",
    "my_file = ''\n",
    "for file in os.listdir(path + 'reg_ru/'):\n",
    "    if '.pkl' in file:\n",
    "        my_file = path + 'reg_ru/' + file\n",
    "        break\n",
    "reg_df = pd.read_pickle(my_file)\n",
    "reg_df = reg_df.domain\n",
    "print(dt.now() - start)\n",
    "print(reg_df.shape)\n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4078909\n",
      "0:03:18.142565\n"
     ]
    }
   ],
   "source": [
    "reg_df = make_diff(reg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download top 1M domains from Alexa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            domain\n",
      "index             \n",
      "1       google.com\n",
      "2      youtube.com\n",
      "(932711, 1)\n",
      "932711\n",
      "0:00:05.247584\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('~/top10milliondomains.csv')\n",
    "# df.head()\n",
    "first_start = dt.now()\n",
    "df =  pd.read_csv('http://s3.amazonaws.com/alexa-static/top-1m.csv.zip', compression='zip', index_col=['index'], names=['index', 'domain'])\n",
    "print(df.head(2))\n",
    "print(df.shape)\n",
    "myset = set(df.domain.values)\n",
    "del df\n",
    "print(len(myset))\n",
    "print(dt.now() - first_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download top 1M domains from AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       domain\n",
      "index                        \n",
      "1                 netflix.com\n",
      "2      api-global.netflix.com\n",
      "(1000000, 1)\n",
      "1000000\n",
      "0:00:09.287192\n"
     ]
    }
   ],
   "source": [
    "start = dt.now()\n",
    "df =  pd.read_csv('http://s3-us-west-1.amazonaws.com/umbrella-static/top-1m.csv.zip', compression='zip', index_col=['index'], names=['index', 'domain'])\n",
    "print(df.head(2))\n",
    "print(df.shape)\n",
    "myset2 = set(df.domain.values)\n",
    "del df\n",
    "print(len(myset2))\n",
    "print(dt.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 1 dataset from Alexa and AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1828376\n"
     ]
    }
   ],
   "source": [
    "myset.update(myset2)\n",
    "all_top = len(myset)\n",
    "print(len(myset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search domains that not in our base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:44.236285\n"
     ]
    }
   ],
   "source": [
    "myset = make_diff(myset)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make first levels domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489504\n",
      "0:00:12.478858\n"
     ]
    }
   ],
   "source": [
    "start = dt.now()\n",
    "myset = [get_top_level_domain(i) for i in myset]\n",
    "myset = set(myset)\n",
    "print(len(myset))\n",
    "df = pd.DataFrame()\n",
    "print(dt.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search first level domains that not in our base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myset = make_diff(myset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make DataFrame from all domains that not in our base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4078909, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make small report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В топе было 1828376 доменов. Из них в базе есть 1440890 (78.8070943832122), нет 387486 (21.192905616787794)\n"
     ]
    }
   ],
   "source": [
    "no_domain = df.shape[0]\n",
    "exist_domain = all_top - no_domain\n",
    "percent_no = no_domain/all_top*100\n",
    "percent_exist = 100 - percent_no\n",
    "print('В топе было {} доменов. Из них в базе есть {} ({}), нет {} ({})'\\\n",
    "      .format(all_top, exist_domain, percent_exist, no_domain, percent_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:50.482709\n"
     ]
    }
   ],
   "source": [
    "print(dt.now() - first_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domains to format for crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0] = df[0].apply(lambda r: 'http://'+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://rosservicelift.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http://mobilart.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://udlinit-gazel.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://olympic-unity.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>http://moplay.ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "0  http://rosservicelift.ru\n",
       "1        http://mobilart.ru\n",
       "2   http://udlinit-gazel.ru\n",
       "3   http://olympic-unity.ru\n",
       "4          http://moplay.ru"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'reg_ru_domain_not_in_base.csv'\n",
    "df.to_csv('~/{}'.format(file_name), sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put file on forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_path = \"https://forest1.getaura.ru/feeds/experimental/{}\".format(file_name)\n",
    "resp = requests.put(put_path, data=open(path + '{}'.format(file_name), 'rb'))\n",
    "if not resp.ok:\n",
    "    print (resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://forest1.getaura.ru/feeds/experimental/reg_ru_domain_not_in_base.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
